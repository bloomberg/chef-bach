#!/usr/bin/python
import urllib2
import json
import sys
import logging
import time
import re
from logging.handlers import RotatingFileHandler
from multiprocessing.pool import ThreadPool as Pool

LOGGER = None

class GraphiteToZabbix(object):

  def __init__(self, threads=1):
    self.cn = self.__class__.__name__
    self.graphite_url = "<%= @graphite_url %>/render?format=json"
    self.default_query_range = "<%= @default_query_range %>"
    self.threads = threads
    self.re_strip_function = re.compile("^(.+\()(.+)(\))$")
    # On applying "self.re_strip_function", which index(start=1) in match.groups has the result
    self.re_query_field = 2
    self._main()

  def create_log(self, path):
    """
    Creates a rotating log
    """

    global LOGGER
    LOGGER = logging.getLogger(__name__)
    LOGGER.setLevel(logging.<%= @log_level %>)
    handler = RotatingFileHandler(path, maxBytes=<%= @max_bytes %>, backupCount=<%= @backup_count %>)
    formatter = logging.Formatter('%(asctime)s %(levelname)s - %(message)s')
    handler.setFormatter(formatter)
    LOGGER.addHandler(handler)

  def query_graphite(self, query_line):
    """
    Query graphite to retrieve monitoring data
    Time out to get a valid response from graphite URL is 30 seconds
    """
    query_target, query_range = query_line.split()
    query_target=query_target.strip()
    query_range=query_range.strip()
    query_string = self.graphite_url + "&from=" + query_range + "&target=" + query_target

    req = urllib2.Request(query_string)

    s_time = time.time()
    data = None
    try:
      response = urllib2.urlopen(req,timeout=30)
      res = response.read()
      data = json.loads(res)
      sys.stdout.write("%s %d %d\n" % ('graphite-to-zabbix graphite-to-zabbix.QueryResultError',int(time.time()),0))
    except Exception as e:
      LOGGER.error('%s, url=%s', e, query_string)
      sys.stdout.write("%s %d %d\n" % ('graphite-to-zabbix graphite-to-zabbix.QueryResultError',int(time.time()),1))
    finally:
      e_time = time.time() - s_time
      LOGGER.debug("%s took %d sec" % (query_target, e_time))
    return data

  def fetch_query_from_function(self, blob_query):
    """
    Parse item part from query
    """

    match_obj = self.re_strip_function.match(blob_query)
    if match_obj:
      blob_query = match_obj.group(self.re_query_field)
    return blob_query

  def get_zbx_keys(self, target):
    """
    Parse the host and item that was queried.
    The format should match the item names in Zabbix.
    """

    query = self.fetch_query_from_function(target)
    parts = query.split('.')
    item = target
    if parts[0] == 'servers':
      # e.g. parts=[u'servers', u'TestLaptop', u'bcpc-vm3', u'diskspace', u'_disk_2', u'byte_avail']
      host = parts[2]
      item = '.'.join(str(s) for s in parts[2:])
    elif parts[0] == 'jmx':
      # e.g. parts=[u'jmx', u'hbase_master', u'Test-Laptop', u'*', u'memory', u'HeapMemoryUsage_committed']
      host = parts[1]
      item = host + '.' + parts[-1]
    return (host, item)

  def write_data(self, data):
    """
    Parse the json object returned by graphite query
    and generate data in the format zabbix_sender protocol needs
    Refer to zabbix sender man pages for details.
    https://www.zabbix.com/documentation/2.4/manpages/zabbix_sender
    """

    for entry in data:
      item_id = "%s %s" % self.get_zbx_keys(entry['target'])
      try:
        output = ["%s %s %d" % (item_id, str(e[1]), int(e[0]) if e[0] else 0) for e in entry['datapoints']]
        sys.stdout.write("%s %d %d\n" % ('graphite-to-zabbix graphite-to-zabbix.QueryResultFormatError',int(time.time()),0))
      except ValueError:
        LOGGER.warn("Error while formatting values for %s" % (item_id))
        sys.stdout.write("%s %d %d\n" % ('graphite-to-zabbix graphite-to-zabbix.QueryResultFormatError',int(time.time()),1))
      if output:
        sys.stdout.write('\n'.join(output) + '\n')

  def process_query(self, query):
    """
    Process a single graphite query
    """
    data = self.query_graphite(query)
    if data:
      self.write_data(data)
      sys.stdout.write("%s %d %d\n" % ('graphite-to-zabbix graphite-to-zabbix.QueryResultEmpty',int(time.time()),0))
    else:
      LOGGER.warn("Returned empty result for query %s" % (query))
      sys.stdout.write("%s %d %d\n" % ('graphite-to-zabbix graphite-to-zabbix.QueryResultEmpty',int(time.time()),1))

  def _main(self):
    self.create_log("<%= @log_file %>")
    LOGGER.info('start')
    with open("<%= @config_file %>",'r') as f:
      queries = f.readlines()
    pool = Pool(processes=self.threads)
    try:
      pool.map(self.process_query, queries)
    except Exception as e:
      LOGGER.error('%s', e)
      pass
    finally:
      pool.close()
      pool.join()
    LOGGER.info('end')

if __name__ == '__main__':
  GraphiteToZabbix(threads=<%= @worker_count %>)
