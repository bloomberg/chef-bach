<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
################################################
#
#              Generated by Chef
#
################################################
-->
<% 
  bucketcache_size = (node["bcpc"]["hadoop"]["hbase_rs"]["xmx"]["size"] * node["bcpc"]["hadoop"]["hbase"]["blockcache"]["size"] + node["bcpc"]["hadoop"]["hbase_rs"]["mx_dir_mem"]["size"]  -  node["bcpc"]["hadoop"]["hbase_rs"]["hdfs_dir_mem"]["size"]).floor 

  bucketcache_combinedcache_percent = bucketcache_size.to_f/(node["bcpc"]["hadoop"]["hbase_rs"]["xmx"]["size"] + node["bcpc"]["hadoop"]["hbase_rs"]["mx_dir_mem"]["size"] -  node["bcpc"]["hadoop"]["hbase_rs"]["hdfs_dir_mem"]["size"])
%>

<configuration>
  <property>
    <name>hbase.rootdir</name>
    <value><%= node['bcpc']['hadoop']['hdfs_url'] %>/hbase</value>
  </property>

  <property>
    <name>hbase.zookeeper.quorum</name>
    <value><%= @zk_hosts.map{ |s| float_host(s[:hostname])}.join(",") %></value> 
  </property>

  <property>
    <name>hbase.zookeeper.property.clientPort</name>
    <value><%= node[:bcpc][:hadoop][:zookeeper][:port] %></value> 
  </property>

  <property>
    <name>hbase.cluster.distributed</name>
    <value>true</value>
  </property>

  <property>
    <name>hbase.hregion.majorcompaction</name>
    <value><%= node["bcpc"]["hadoop"]["hbase"]["major_compact"]["time"] %></value>
  </property>

  <property>
    <name>fail.fast.expired.active.master</name>
    <value><%= @master_hosts.length > 1 ? "true" : "false" %></value>
  </property>

  <property>
    <name>hbase.master.wait.on.regionservers.mintostart</name>
    <value><%= @rs_hosts.length/2+1 %></value>
  </property>

  <property>
    <name>hbase.regionserver.dns.interface</name>
    <value><%= node["bcpc"]["floating"]["interface"] %></value> 
  </property>

  <property>
    <name>hbase.master.dns.interface</name>
    <value><%= node["bcpc"]["floating"]["interface"] %></value> 
  </property>

  <property>
    <name>hbase.regionserver.ipc.address</name>
    <value><%= node["bcpc"]["floating"]["ip"] %></value> 
  </property>

  <property>
    <name>hbase.master.ipc.address</name>
    <value><%= node["bcpc"]["floating"]["ip"] %></value> 
  </property>

  <property>
    <name>hbase.regionserver.dns.nameserver</name>
    <value><%= @dns_server %></value> 
  </property>

  <property>
    <name>hbase.master.dns.nameserver</name>
    <value><%= @dns_server %></value> 
  </property>

  <property>
    <name>hbase.defaults.for.version.skip</name>
    <value>true</value>
  </property>

  <property>
    <name>hbase.regionserver.wal.codec</name>
    <value>org.apache.hadoop.hbase.regionserver.wal.IndexedWALEditCodec</value>
  </property>

  <property>
    <name>hbase.region.server.rpc.scheduler.factory.class</name>
    <value>org.apache.phoenix.hbase.index.ipc.PhoenixIndexRpcSchedulerFactory</value>
    <description>Factory to create the Phoenix RPC Scheduler that knows to put index updates into index queues</description>
  </property>

  <% if node[:bcpc][:hadoop][:kerberos][:enable] == true then %>
  <!-- HBase Authorization Configuration -->
  <property> 
    <name>hbase.security.authorization</name> 
    <value>true</value> 
  </property> 

  <property>    
    <name>hbase.superuser</name>    
    <value><%= node[:bcpc][:hadoop][:hbase][:superusers].join(",") %></value>    
    <description>List of users or groups (comma-separated), who are allowed full privileges, regardless of stored ACLs, across the cluster. Only used when HBase security is enabled.</description>
  </property>

  <property>    
    <name>hbase.coprocessor.region.classes</name>    
    <value>org.apache.hadoop.hbase.security.token.TokenProvider,org.apache.hadoop.hbase.security.access.SecureBulkLoadEndpoint,org.apache.hadoop.hbase.security.access.AccessController</value>
    <description>A comma-separated list of Coprocessors that are loaded by default on all tables.</description>  
  </property>

  <property>
    <name>hbase.security.exec.permission.checks</name>
    <value>true</value>
  </property>

  <property>    
    <name>hbase.coprocessor.regionserver.classes</name>    
    <value>org.apache.hadoop.hbase.security.access.AccessController</value>    
  </property> 

  <property>    
    <name>hbase.coprocessor.master.classes</name>    
    <value>org.apache.hadoop.hbase.security.access.AccessController</value>    
  </property> 

  <!-- HBase Security Configuration -->
  <property> 
    <name>hbase.security.authentication</name> 
    <value>kerberos</value> 
  </property> 

  <property>
    <name>hbase.master.kerberos.principal</name>
    <value><%= node[:bcpc][:hadoop][:kerberos][:data][:hbase][:principal] %>/<%=node[:bcpc][:hadoop][:kerberos][:data][:hbase][:princhost] == "_HOST" ? "_HOST" : node[:bcpc][:hadoop][:kerberos][:data][:hbase][:princhost]%>@<%= node[:bcpc][:hadoop][:kerberos][:realm] %></value>
  </property>

  <property> 
    <name>hbase.master.keytab.file</name> 
    <value><%= node[:bcpc][:hadoop][:kerberos][:keytab][:dir] %>/<%= node[:bcpc][:hadoop][:kerberos][:data][:hbase][:keytab] %></value> 
    <description>Full path to the kerberos keytab file to use for logging in the configured HMaster server principal.</description> 
  </property> 

  <property>
    <name>hbase.regionserver.kerberos.principal</name>
    <value><%= node[:bcpc][:hadoop][:kerberos][:data][:hbase][:principal] %>/<%=node[:bcpc][:hadoop][:kerberos][:data][:hbase][:princhost] == "_HOST" ? "_HOST" : node[:bcpc][:hadoop][:kerberos][:data][:hbase][:princhost]%>@<%= node[:bcpc][:hadoop][:kerberos][:realm] %></value>
  </property>

  <property> 
    <name>hbase.regionserver.keytab.file</name> 
    <value><%= node[:bcpc][:hadoop][:kerberos][:keytab][:dir] %>/<%= node[:bcpc][:hadoop][:kerberos][:data][:hbase][:keytab] %></value> 
    <description>Full path to the kerberos keytab file to use for logging in the configured HRegionServer server principal.</description> 
  </property> 

  <property>    
    <name>hbase.rpc.engine</name>    
    <value>org.apache.hadoop.hbase.ipc.SecureRpcEngine</value>    
  </property>   
  <% end %>

  <property>
    <name>dfs.client.read.shortcircuit</name>
    <value><%= node["bcpc"]["hadoop"]["hbase"]["shortcircuit"]["read"]%></value>
  </property>

  <% if node["bcpc"]["hadoop"]["hbase"]["shortcircuit"]["read"] == true then %>
  <property>
    <name>dfs.domain.socket.path</name>
    <value>/var/run/hadoop-hdfs/dn._PORT</value>
  </property>

  <property>
    <name>dfs.client.read.shortcircuit.buffer.size</name>
    <value>131072</value>
  </property>
  <% end %>

  <property>
    <name>hbase.regionserver.handler.count</name>
    <value>128</value>
  </property>

  <!-- Log responses which take longer than 250ms -->
  <property>
    <name>hbase.ipc.warn.response.time</name>
    <value><%= node["bcpc"]["hadoop"]["hbase"]["ipc"]["warn"]["responsetime"]%></value>
  </property>

  <!-- Log responses which are larger than 1MB -->
  <property>
    <name>hbase.ipc.warn.response.size</name>
    <value>1048576</value>
  </property>

  <property>
    <name>hbase.ipc.server.tcpnodelay</name>
    <value>true</value>
  </property>

  <% if node["bcpc"]["hadoop"]["hbase"]["bucketcache"]["enabled"] == true then %>
  <property>
    <name>hbase.regionserver.global.memstore.upperLimit</name>
    <value><%= node["bcpc"]["hadoop"]["hbase_rs"]["memstore"]["upperlimit"]%></value>
  </property>

  <property>
    <name>hfile.block.cache.size</name>
    <value><%= node["bcpc"]["hadoop"]["hbase"]["blockcache"]["size"]%></value>
  </property>
  
  <property>
    <name>hbase.bucketcache.size</name>
    <value><%= bucketcache_size%></value>
  </property>

  <property>
    <name>hbase.bucketcache.ioengine </name>
    <value><%= node["bcpc"]["hadoop"]["hbase"]["bucketcache"]["ioengine"]%></value>
  </property>

  <property>
    <name>hbase.bucketcache.percentage.in.combinedcache</name>
    <value><%= bucketcache_combinedcache_percent%></value>
  </property>
  <% end %>

  <% if node["bcpc"]["hadoop"]["hbase"]["region"]["replication"]["enabled"] == true then %>
  <property>
    <name>hbase.regionserver.storefile.refresh.period</name>
    <value><%= node["bcpc"]["hadoop"]["hbase_rs"]["storefile"]["refresh"]["period"]%></value>
  </property>

  <property>
    <name>hbase.region.replica.replication.enabled</name>
    <value><%= node["bcpc"]["hadoop"]["hbase"]["region"]["replication"]["enabled"]%></value>
  </property>

  <property>
    <name>hbase.master.hfilecleaner.ttl</name>
    <value><%= node["bcpc"]["hadoop"]["hbase_master"]["hfilecleaner"]["ttl"]%></value>
  </property>

  <property>
    <name>hbase.meta.replica.count</name>
    <value><%= node["bcpc"]["hadoop"]["hbase"]["meta"]["replica"]["count"]%></value>
  </property>

  <property>
    <name>hbase.regionserver.storefile.refresh.all</name>
    <value><%= node["bcpc"]["hadoop"]["hbase_rs"]["storefile"]["refresh"]["all"]%></value>
  </property>

  <property>
    <name>hbase.region.replica.storefile.refresh.memstore.multiplier</name>
    <value><%= node["bcpc"]["hadoop"]["hbase"]["region"]["replica"]["storefile"]["refresh"]["memstore"]["multiplier"]%></value>
  </property>

  <property>
    <name>hbase.region.replica.wait.for.primary.flush</name>
    <value><%= node["bcpc"]["hadoop"]["hbase"]["region"]["replica"]["wait"]["for"]["primary"]["flush"]%></value>
  </property>

  <property>
    <name>hbase.regionserver.global.memstore.lowerLimit</name>
    <value><%= node["bcpc"]["hadoop"]["hbase_rs"]["memstore"]["lowerlimit"]%></value>
  </property>

  <property>
    <name>hbase.hregion.memstore.block.multiplier</name>
    <value><%= node["bcpc"]["hadoop"]["hbase"]["hregion"]["memstore"]["block"]["multiplier"]%></value>
  </property>

  <property>
    <name>hbase.ipc.client.specificThreadForWriting</name>
    <value><%= node["bcpc"]["hadoop"]["hbase"]["ipc"]["client"]["specificthreadforwriting"]%></value>
  </property>

  <property>
    <name>hbase.client.primaryCallTimeout.get</name>
    <value><%= node["bcpc"]["hadoop"]["hbase"]["client"]["primarycalltimeout"]["get"]%></value>
  </property>

  <property>
    <name>hbase.client.primaryCallTimeout.multiget</name>
    <value><%= node["bcpc"]["hadoop"]["hbase"]["client"]["primarycalltimeout"]["multiget"]%></value>
  </property>
  <% end %>

  <property>
    <name>hbase.replication</name>
    <value>true</value>
  </property>

  <property>
    <name>hbase.coprocessor.abortonerror</name>
    <value><%= node["bcpc"]["hadoop"]["hbase_rs"]["coprocessor"]["abortonerror"] %></value>
  </property>
</configuration>
